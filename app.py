import streamlit as st
import time
import datetime
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import json
from utils.pricing import calculate_price
from utils.llm_handler import call_llm, MockLLMHandler
from config import (
    OPENAI_MODELS, 
    GEMINI_MODELS, 
    DEFAULT_TEMPERATURE,
    DEFAULT_MAX_TOKENS,
    DEFAULT_PROMPT
)


st.set_page_config(page_title="LLMãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚¢ãƒ—ãƒª", layout="wide")

st.title("LLMãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã‚¢ãƒ—ãƒª")
st.write("ã“ã®ã‚¢ãƒ—ãƒªã¯ã€è¤‡æ•°ã®LLMãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›çµæœã¨å®Ÿè¡Œé€Ÿåº¦ã€ã‚³ã‚¹ãƒˆã‚’æ¯”è¼ƒã—ã¾ã™ã€‚")

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã®åˆæœŸåŒ–
if 'mock_mode' not in st.session_state:
    st.session_state['mock_mode'] = True

# APIã‚­ãƒ¼ã®çŠ¶æ…‹ç¢ºèªç”¨
if 'has_openai_key' not in st.session_state:
    st.session_state['has_openai_key'] = False
if 'has_google_key' not in st.session_state:
    st.session_state['has_google_key'] = False

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ãƒ¢ãƒ¼ãƒ‰é¸æŠã¨è¨­å®šã‚’é…ç½®
with st.sidebar:
    # ãƒ¢ãƒƒã‚¯/æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆ
    st.header("ãƒ¢ãƒ¼ãƒ‰è¨­å®š")
    mock_mode = st.checkbox("ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ï¼ˆAPIã‚’ä½¿ç”¨ã—ãªã„ï¼‰", value=True)
    st.session_state['mock_mode'] = mock_mode
    
    if not mock_mode:
        # æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰æ™‚ã®APIã‚­ãƒ¼è¨­å®š
        st.header("API Keys")
        openai_api_key = st.text_input("OpenAI API Key", type="password")
        google_api_key = st.text_input("Google API Key", type="password")
        
        # APIã‚­ãƒ¼ã®çŠ¶æ…‹ç¢ºèª
        st.session_state['has_openai_key'] = bool(openai_api_key)
        st.session_state['has_google_key'] = bool(google_api_key)
        
        if not openai_api_key:
            st.warning("OpenAIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯API Keyã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
        if not google_api_key:
            st.warning("Geminiãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã«ã¯API Keyã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰æ™‚ã¯APIã‚­ãƒ¼ä¸è¦
        openai_api_key = "mock_key"
        google_api_key = "mock_key"
        st.session_state['has_openai_key'] = True
        st.session_state['has_google_key'] = True
        st.info("ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã¯APIã‚­ãƒ¼ã¯ä¸è¦ã§ã™")
    
    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    st.header("ãƒ¢ãƒ‡ãƒ«é¸æŠ")
    
    # OpenAIãƒ¢ãƒ‡ãƒ«é¸æŠ
    openai_models = st.multiselect(
        "OpenAIãƒ¢ãƒ‡ãƒ«",
        OPENAI_MODELS,
        default=[OPENAI_MODELS[0]]
    )
    
    # Geminiãƒ¢ãƒ‡ãƒ«é¸æŠ
    gemini_models = st.multiselect(
        "Geminiãƒ¢ãƒ‡ãƒ«",
        GEMINI_MODELS,
        default=[GEMINI_MODELS[0]]
    )
    
    # å®Ÿè¡Œè¨­å®š
    st.header("å®Ÿè¡Œè¨­å®š")
    temperature = st.slider("Temperature", min_value=0.0, max_value=1.0, value=DEFAULT_TEMPERATURE, step=0.1)
    max_tokens = st.slider("æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°", min_value=50, max_value=1000, value=DEFAULT_MAX_TOKENS, step=50)

# ãƒ¡ã‚¤ãƒ³ç”»é¢è¨­å®š
st.header("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå…¥åŠ›")
user_prompt = st.text_area("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„", value=DEFAULT_PROMPT, height=150)

# ãƒ¢ãƒƒã‚¯ãƒãƒ³ãƒ‰ãƒ©ã®åˆæœŸåŒ–
mock_handler = MockLLMHandler()

# å®Ÿè¡Œãƒœã‚¿ãƒ³
if st.button("å®Ÿè¡Œ", type="primary"):
    if not user_prompt:
        st.error("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    elif not (openai_models or gemini_models):
        st.error("å°‘ãªãã¨ã‚‚1ã¤ã®ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„")
    else:
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # çµæœã‚’ä¿å­˜ã™ã‚‹ãƒªã‚¹ãƒˆ
        results = []
        
        # å®Ÿè¡Œã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã®ç·æ•°ã‚’è¨ˆç®—
        total_models = len(openai_models) + len(gemini_models)
        current_model = 0
        
        # OpenAIãƒ¢ãƒ‡ãƒ«ã®å®Ÿè¡Œ
        if openai_models and st.session_state['has_openai_key']:
            for model in openai_models:
                current_model += 1
                progress = int(current_model / total_models * 100)
                progress_bar.progress(progress)
                status_text.text(f"å®Ÿè¡Œä¸­: {model} ({progress}%)")
                
                if st.session_state['mock_mode']:
                    # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã®å®Ÿè¡Œ
                    output, exec_time, input_tokens, output_tokens = mock_handler.call_llm(
                        model, "OpenAI", user_prompt, temperature, max_tokens
                    )
                else:
                    # å®Ÿéš›ã®APIã§ã®å®Ÿè¡Œ
                    try:
                        output, exec_time, input_tokens, output_tokens = call_llm(
                            model, "OpenAI", user_prompt, temperature, max_tokens, openai_api_key
                        )
                    except Exception as e:
                        st.error(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {str(e)}")
                        continue
                
                # æ–™é‡‘è¨ˆç®—
                pricing = calculate_price("OpenAI", model, input_tokens, output_tokens)
                
                results.append({
                    "ãƒ¢ãƒ‡ãƒ«": model,
                    "ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼": "OpenAI",
                    "å®Ÿè¡Œæ™‚é–“(ç§’)": round(exec_time, 2),
                    "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°": input_tokens,
                    "å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°": output_tokens,
                    "ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°": input_tokens + output_tokens,
                    "APIåˆ©ç”¨æ–™é‡‘": pricing["formatted_total"],
                    "APIåˆ©ç”¨æ–™é‡‘(æ•°å€¤)": pricing["total"],
                    "å…¥åŠ›ã‚³ã‚¹ãƒˆ": pricing["input_cost"],
                    "å‡ºåŠ›ã‚³ã‚¹ãƒˆ": pricing["output_cost"],
                    "å‡ºåŠ›": output
                })
        
        # Geminiãƒ¢ãƒ‡ãƒ«ã®å®Ÿè¡Œ
        if gemini_models and st.session_state['has_google_key']:
            for model in gemini_models:
                current_model += 1
                progress = int(current_model / total_models * 100)
                progress_bar.progress(progress)
                status_text.text(f"å®Ÿè¡Œä¸­: {model} ({progress}%)")
                
                if st.session_state['mock_mode']:
                    # ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰ã§ã®å®Ÿè¡Œ
                    output, exec_time, input_tokens, output_tokens = mock_handler.call_llm(
                        model, "Google", user_prompt, temperature, max_tokens
                    )
                else:
                    # å®Ÿéš›ã®APIã§ã®å®Ÿè¡Œ
                    try:
                        output, exec_time, input_tokens, output_tokens = call_llm(
                            model, "Google", user_prompt, temperature, max_tokens, google_api_key
                        )
                    except Exception as e:
                        st.error(f"Google Gemini APIã‚¨ãƒ©ãƒ¼: {str(e)}")
                        continue
                
                # æ–™é‡‘è¨ˆç®—
                pricing = calculate_price("Google", model, input_tokens, output_tokens)
                
                results.append({
                    "ãƒ¢ãƒ‡ãƒ«": model,
                    "ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼": "Google",
                    "å®Ÿè¡Œæ™‚é–“(ç§’)": round(exec_time, 2),
                    "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°": input_tokens,
                    "å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°": output_tokens,
                    "ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°": input_tokens + output_tokens,
                    "APIåˆ©ç”¨æ–™é‡‘": pricing["formatted_total"],
                    "APIåˆ©ç”¨æ–™é‡‘(æ•°å€¤)": pricing["total"],
                    "å…¥åŠ›ã‚³ã‚¹ãƒˆ": pricing["input_cost"],
                    "å‡ºåŠ›ã‚³ã‚¹ãƒˆ": pricing["output_cost"],
                    "å‡ºåŠ›": output
                })
        
        # é€²æ—è¡¨ç¤ºã‚’ã‚¯ãƒªã‚¢
        progress_bar.empty()
        status_text.empty()
        
        # çµæœã®è¡¨ç¤º
        if results:
            # DataFrameã«å¤‰æ›
            df = pd.DataFrame(results)
            
            # 2ã‚«ãƒ©ãƒ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
            col1, col2 = st.columns(2)
            
            with col1:
                # å®Ÿè¡Œæ™‚é–“ã‚°ãƒ©ãƒ•ã®è¡¨ç¤º
                st.header("å®Ÿè¡Œæ™‚é–“æ¯”è¼ƒ")
                
                # ã‚«ãƒ©ãƒ¼ãƒãƒƒãƒ—ã®è¨­å®š
                color_map = {"OpenAI": "#00A67E", "Google": "#4285F4"}
                
                # Plotlyã§ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ
                fig = px.bar(
                    df, 
                    x="ãƒ¢ãƒ‡ãƒ«", 
                    y="å®Ÿè¡Œæ™‚é–“(ç§’)", 
                    color="ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼",
                    color_discrete_map=color_map,
                    text=df["å®Ÿè¡Œæ™‚é–“(ç§’)"].apply(lambda x: f"{x:.2f}s"),
                    height=400,
                    title="å„ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè¡Œæ™‚é–“æ¯”è¼ƒ"
                )
                
                # ã‚°ãƒ©ãƒ•ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
                fig.update_layout(
                    xaxis_title="ãƒ¢ãƒ‡ãƒ«",
                    yaxis_title="å®Ÿè¡Œæ™‚é–“ (ç§’)",
                    legend_title="ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼",
                    font=dict(size=14),
                    xaxis={'categoryorder':'total descending'},
                    hovermode="x unified"
                )
                
                # ãƒ†ã‚­ã‚¹ãƒˆã®ä½ç½®èª¿æ•´
                fig.update_traces(
                    textposition='outside',
                    textfont=dict(size=14)
                )
                
                # Tooltipã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
                fig.update_traces(
                    hovertemplate="<b>%{x}</b><br>å®Ÿè¡Œæ™‚é–“: %{y:.2f}ç§’<br>ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: %{marker.color}"
                )
                
                # ãƒ—ãƒ­ãƒƒãƒˆã®è¡¨ç¤º
                st.plotly_chart(fig, use_container_width=True)
                
                # ã‚³ã‚¹ãƒˆæ¯”è¼ƒã‚°ãƒ©ãƒ•
                st.header("APIåˆ©ç”¨æ–™é‡‘æ¯”è¼ƒ")
                
                fig = px.bar(
                    df, 
                    x="ãƒ¢ãƒ‡ãƒ«", 
                    y="APIåˆ©ç”¨æ–™é‡‘(æ•°å€¤)", 
                    color="ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼",
                    color_discrete_map=color_map,
                    text=df["APIåˆ©ç”¨æ–™é‡‘"],
                    height=400,
                    title="å„ãƒ¢ãƒ‡ãƒ«ã®APIåˆ©ç”¨æ–™é‡‘æ¯”è¼ƒ"
                )
                
                # ã‚°ãƒ©ãƒ•ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´
                fig.update_layout(
                    xaxis_title="ãƒ¢ãƒ‡ãƒ«",
                    yaxis_title="ã‚³ã‚¹ãƒˆ (USD)",
                    legend_title="ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼",
                    font=dict(size=14),
                    xaxis={'categoryorder':'total descending'},
                    hovermode="x unified"
                )
                
                # ãƒ†ã‚­ã‚¹ãƒˆã®ä½ç½®èª¿æ•´
                fig.update_traces(
                    textposition='outside',
                    textfont=dict(size=14)
                )
                
                # Tooltipã®ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
                fig.update_traces(
                    hovertemplate="<b>%{x}</b><br>ã‚³ã‚¹ãƒˆ: %{text}<br>ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼: %{marker.color}"
                )
                
                # ãƒ—ãƒ­ãƒƒãƒˆã®è¡¨ç¤º
                st.plotly_chart(fig, use_container_width=True)
                
                # ä½¿ç”¨çµ±è¨ˆï¼ˆPlotlyã®ãƒ†ãƒ¼ãƒ–ãƒ«ã§è¡¨ç¤ºï¼‰
                st.subheader("ä½¿ç”¨çµ±è¨ˆ")
                
                # ãƒ†ãƒ¼ãƒ–ãƒ«ç”¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ä½œæˆ
                stats_df = df[["ãƒ¢ãƒ‡ãƒ«", "ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼", "å®Ÿè¡Œæ™‚é–“(ç§’)", 
                             "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°", "å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°", "ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°", "APIåˆ©ç”¨æ–™é‡‘"]].copy()
                
                # ã‚«ãƒ©ãƒ¼å®šç¾©
                fill_colors = []
                for provider in stats_df["ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼"]:
                    if provider == "OpenAI":
                        fill_colors.append(['#E5F6F0', '#E5F6F0', '#E5F6F0', '#E5F6F0', '#E5F6F0', '#E5F6F0', '#E5F6F0'])
                    else:
                        fill_colors.append(['#E8F0FE', '#E8F0FE', '#E8F0FE', '#E8F0FE', '#E8F0FE', '#E8F0FE', '#E8F0FE'])
                
                # Plotlyã®ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
                fig = go.Figure(data=[go.Table(
                    header=dict(
                        values=list(stats_df.columns),
                        fill_color='#F0F2F6',
                        align='left',
                        font=dict(size=14)
                    ),
                    cells=dict(
                        values=[stats_df[col] for col in stats_df.columns],
                        fill_color=fill_colors,
                        align='left',
                        font=dict(size=13)
                    )
                )])
                
                fig.update_layout(
                    margin=dict(l=0, r=0, t=0, b=0),
                    height=250
                )
                
                st.plotly_chart(fig, use_container_width=True)
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                st.subheader("å®Ÿè¡Œæƒ…å ±")
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ç”¨æ„
                metadata = {
                    "å®Ÿè¡Œæ—¥æ™‚": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                    "ä½¿ç”¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—æ•°": len(user_prompt),
                    "Temperatureè¨­å®š": temperature,
                    "æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°": max_tokens,
                    "ãƒ¢ãƒ¼ãƒ‰": "ãƒ¢ãƒƒã‚¯ãƒ¢ãƒ¼ãƒ‰" if st.session_state['mock_mode'] else "æœ¬ç•ªãƒ¢ãƒ¼ãƒ‰"
                }
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¦–è¦šçš„ã«è¡¨ç¤º
                col1_meta, col2_meta = st.columns(2)
                
                with col1_meta:
                    st.metric("ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—æ•°", len(user_prompt))
                    st.metric("æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°", max_tokens)
                
                with col2_meta:
                    st.metric("Temperatureè¨­å®š", f"{temperature:.1f}")
                    st.metric("ãƒ¢ãƒ¼ãƒ‰", "ãƒ¢ãƒƒã‚¯" if st.session_state['mock_mode'] else "æœ¬ç•ª")
                
                # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã®ãƒ‰ãƒ¼ãƒŠãƒ„ãƒãƒ£ãƒ¼ãƒˆ
                token_data = stats_df[["ãƒ¢ãƒ‡ãƒ«", "ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°"]].copy()
                
                fig = px.pie(
                    token_data, 
                    values="ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°", 
                    names="ãƒ¢ãƒ‡ãƒ«", 
                    hole=.4,
                    color="ãƒ¢ãƒ‡ãƒ«",
                    title="ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã®åˆ†å¸ƒ"
                )
                
                fig.update_layout(
                    showlegend=True,
                    height=300,
                    margin=dict(t=30, b=0, l=0, r=0)
                )
                
                st.plotly_chart(fig, use_container_width=True)
            
            with col2:
                # å„ãƒ¢ãƒ‡ãƒ«ã®å‡ºåŠ›çµæœã‚’è¡¨ç¤º
                st.header("å‡ºåŠ›çµæœ")
                
                # ã‚¿ãƒ–å½¢å¼ã§çµæœã‚’è¡¨ç¤º
                model_tabs = st.tabs([f"{r['ãƒ¢ãƒ‡ãƒ«']}" for r in results])
                for i, tab in enumerate(model_tabs):
                    with tab:
                        result = results[i]
                        
                        # ãƒ¢ãƒ‡ãƒ«æƒ…å ±ã‚’ã‚«ãƒ©ãƒ¼ãƒœãƒƒã‚¯ã‚¹ã§è¡¨ç¤º
                        provider_color = "#00A67E" if result['ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼'] == "OpenAI" else "#4285F4"
                        st.markdown(
                            f"""
                            <div style="background-color:{provider_color}; color:white; padding:10px; border-radius:5px; margin-bottom:10px;">
                                <span style="font-size:1.2em; font-weight:bold;">{result['ãƒ¢ãƒ‡ãƒ«']}</span> | 
                                {result['ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼']} | 
                                å®Ÿè¡Œæ™‚é–“: {result['å®Ÿè¡Œæ™‚é–“(ç§’)']}ç§’ | 
                                ã‚³ã‚¹ãƒˆ: {result['APIåˆ©ç”¨æ–™é‡‘']}
                            </div>
                            """, 
                            unsafe_allow_html=True
                        )
                        
                        # ãƒˆãƒ¼ã‚¯ãƒ³æƒ…å ±è¡¨ç¤º
                        st.markdown(
                            f"""
                            **ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡**: 
                            å…¥åŠ›: {result['å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°']} | 
                            å‡ºåŠ›: {result['å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°']} | 
                            åˆè¨ˆ: {result['ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°']}
                            """
                        )
                        
                        # å‡ºåŠ›çµæœã‚’è¡¨ç¤º
                        st.text_area(
                            "ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›",
                            result["å‡ºåŠ›"],
                            height=350,
                            key=f"result_{i}"
                        )
                        
                        # ã‚·ãƒ³ãƒ—ãƒ«ãªè©•ä¾¡ãƒœã‚¿ãƒ³
                        col_thumbs = st.columns([1, 1, 5])
                        with col_thumbs[0]:
                            st.button("ğŸ‘ è‰¯ã„", key=f"good_{i}")
                        with col_thumbs[1]:
                            st.button("ğŸ‘ æ‚ªã„", key=f"bad_{i}")
                
                # ãƒ¢ãƒ‡ãƒ«é–“ã®æ¯”è¼ƒãƒšãƒ¼ã‚¸ã‚’è¿½åŠ 
                st.subheader("âš–ï¸ ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ")
                
                if len(results) >= 2:
                    # æ¯”è¼ƒã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ
                    col_comp1, col_comp2 = st.columns(2)
                    with col_comp1:
                        comp_model1 = st.selectbox("ãƒ¢ãƒ‡ãƒ«1", options=[r["ãƒ¢ãƒ‡ãƒ«"] for r in results], index=0)
                    with col_comp2:
                        comp_model2 = st.selectbox("ãƒ¢ãƒ‡ãƒ«2", options=[r["ãƒ¢ãƒ‡ãƒ«"] for r in results], index=min(1, len(results)-1))
                    
                    # é¸æŠã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    result1 = next((r for r in results if r["ãƒ¢ãƒ‡ãƒ«"] == comp_model1), None)
                    result2 = next((r for r in results if r["ãƒ¢ãƒ‡ãƒ«"] == comp_model2), None)
                    
                    # æ¯”è¼ƒãƒ“ãƒ¥ãƒ¼ã‚’è¡¨ç¤º
                    if result1 and result2 and result1 != result2:
                        # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒã®çµ±è¨ˆè¡¨ç¤º
                        comp_stats = pd.DataFrame({
                            "æŒ‡æ¨™": ["å®Ÿè¡Œæ™‚é–“(ç§’)", "å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°", "å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°", "ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°", "APIåˆ©ç”¨æ–™é‡‘"],
                            result1['ãƒ¢ãƒ‡ãƒ«']: [
                                result1['å®Ÿè¡Œæ™‚é–“(ç§’)'],
                                result1['å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°'],
                                result1['å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°'],
                                result1['ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°'],
                                result1['APIåˆ©ç”¨æ–™é‡‘']
                            ],
                            result2['ãƒ¢ãƒ‡ãƒ«']: [
                                result2['å®Ÿè¡Œæ™‚é–“(ç§’)'],
                                result2['å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°'],
                                result2['å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°'],
                                result2['ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°'],
                                result2['APIåˆ©ç”¨æ–™é‡‘']
                            ],
                            "å·®ç•°": [
                                f"{round(result1['å®Ÿè¡Œæ™‚é–“(ç§’)'] - result2['å®Ÿè¡Œæ™‚é–“(ç§’)'], 2)}ç§’",
                                result1['å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°'] - result2['å…¥åŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°'],
                                result1['å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°'] - result2['å‡ºåŠ›ãƒˆãƒ¼ã‚¯ãƒ³æ•°'],
                                result1['ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°'] - result2['ç·ãƒˆãƒ¼ã‚¯ãƒ³æ•°'],
                                f"${round(result1['APIåˆ©ç”¨æ–™é‡‘(æ•°å€¤)'] - result2['APIåˆ©ç”¨æ–™é‡‘(æ•°å€¤)'], 6)}"
                            ]
                        })
                        
                        st.dataframe(comp_stats, use_container_width=True)
                        
                        # å‡ºåŠ›æ¯”è¼ƒ
                        col_view1, col_view2 = st.columns(2)
                        with col_view1:
                            provider_color1 = "#00A67E" if result1['ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼'] == "OpenAI" else "#4285F4"
                            st.markdown(f"<span style='color:{provider_color1}; font-weight:bold;'>{result1['ãƒ¢ãƒ‡ãƒ«']}</span>", unsafe_allow_html=True)
                            st.text_area("", result1["å‡ºåŠ›"], height=250, key="comp_1")
                        with col_view2:
                            provider_color2 = "#00A67E" if result2['ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼'] == "OpenAI" else "#4285F4"
                            st.markdown(f"<span style='color:{provider_color2}; font-weight:bold;'>{result2['ãƒ¢ãƒ‡ãƒ«']}</span>", unsafe_allow_html=True)
                            st.text_area("", result2["å‡ºåŠ›"], height=250, key="comp_2")
            
            # çµæœã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            csv_data = df.drop(columns=["å‡ºåŠ›"]).to_csv(index=False).encode('utf-8')
            st.download_button(
                label="çµæœã‚’CSVã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=csv_data,
                file_name=f'llm_comparison_{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}.csv',
                mime='text/csv',
            )
            
            # è©³ç´°çµæœã®JSONãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚‚æä¾›
            json_results = []
            for r in results:
                json_result = r.copy()
                # æ•°å€¤ã®ä¸¸ã‚ãªã©ã®å‡¦ç†
                json_result["å®Ÿè¡Œæ™‚é–“(ç§’)"] = round(json_result["å®Ÿè¡Œæ™‚é–“(ç§’)"], 3)
                json_result["APIåˆ©ç”¨æ–™é‡‘(æ•°å€¤)"] = round(json_result["APIåˆ©ç”¨æ–™é‡‘(æ•°å€¤)"], 6)
                json_results.append(json_result)
                
            json_data = json.dumps(json_results, ensure_ascii=False, indent=2).encode('utf-8')
            st.download_button(
                label="è©³ç´°çµæœã‚’JSONã¨ã—ã¦ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=json_data,
                file_name=f'llm_comparison_detail_{datetime.datetime.now().strftime("%Y%m%d_%H%M%S")}.json',
                mime='application/json',
            )
